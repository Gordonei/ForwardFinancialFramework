{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Partitioning Verification Experiment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aim: \n",
      "* Verify that the approach to modelling the runtime characteristics of execution of tasks upon various platforms is correct, and that the \n",
      "* Verify the SCIP-based partitioner schedule based upon these model inputs"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Option Pricing Tasks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The options all have non-zero values for reasonably small numbers of tasks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "options = []\n",
      "with open('valid_seeds_file.csv','r') as valid_seeds_file:\n",
      "    csvreader = csv.DictReader(valid_seeds_file,delimiter=',')\n",
      "    options = [row for row in csvreader]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tasks = {}\n",
      "for o in options:\n",
      "    temp_task = \"%s %s\"%(o['underlying'],o['option'])\n",
      "    if(temp_task not in tasks): tasks[temp_task] = 0\n",
      "    tasks[temp_task] += 1\n",
      "    \n",
      "print(\"Portfolio of Option Pricing Tasks\")\n",
      "total = 0\n",
      "for t in sorted(tasks):\n",
      "    print(\"%s: %d\"%(t,tasks[t]))\n",
      "    total += tasks[t]\n",
      "    \n",
      "print(\"total tasks:%d\"%total)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Portfolio of Option Pricing Tasks\n",
        "black_scholes asian: 10\n",
        "black_scholes barrier: 10\n",
        "black_scholes digital_double_barrier: 5\n",
        "black_scholes double_barrier: 10\n",
        "heston asian: 25\n",
        "heston barrier: 29\n",
        "heston digital_double_barrier: 5\n",
        "heston double_barrier: 29\n",
        "heston european: 5\n",
        "total tasks:128\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compile_string = \"\"\n",
      "for t in tasks: compile_string += \"python mc_solver_option_test.py CPU \\\"Generate Compile\\\" 1000 \\\"%s 1234\\\";\"%t\n",
      "print(compile_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"black_scholes barrier 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"heston european 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"heston barrier 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"heston double_barrier 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"black_scholes asian 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"heston digital_double_barrier 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"black_scholes double_barrier 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"heston asian 1234\";python mc_solver_option_test.py CPU \"Generate Compile\" 1000 \"black_scholes digital_double_barrier 1234\";\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ForwardFinancialFramework.bin.option_generator as option_generator\n",
      "\n",
      "option_tasks = [option_generator.generate_option(int(o['seed']),underlying_type=o['underlying'],option_type=o['option']) for o in options]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Platforms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ForwardFinancialFramework.Platforms.MulticoreCPU import MulticoreCPU_MonteCarlo, MulticoreCPU\n",
      "from ForwardFinancialFramework.Platforms.OpenCLGPU import OpenCLGPU_MonteCarlo,OpenCLGPU\n",
      "from ForwardFinancialFramework.Platforms.OpenCLAlteraFPGA import OpenCLAlteraFPGA_MonteCarlo,OpenCLAlteraFPGA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Local Platform"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms = [MulticoreCPU.MulticoreCPU()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Remote CPUs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms += [MulticoreCPU.MulticoreCPU(remote=True,ssh_alias=\"ee-benjamin\"),MulticoreCPU.MulticoreCPU(remote=True,ssh_alias=\"pi\"),MulticoreCPU.MulticoreCPU(remote=True,ssh_alias=\"ee-mollie\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Remote GPUs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms += [OpenCLGPU.OpenCLGPU(remote=True,ssh_alias=\"ee-snowball0\"),OpenCLGPU.OpenCLGPU(remote=True,ssh_alias=\"ee-snowball1\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Remote FPGAs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms += [OpenCLAlteraFPGA.OpenCLAlteraFPGA(remote=True,ssh_alias=\"ee-snowball2\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Verifying the Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Model Verification Procedure:\n",
      "    1. Run each task for up to (5 minutes)/128 on each platform\n",
      "    2. Generate Latency, Accuracy and Latency-Accuracy models for each task.\n",
      "    3. Combine the task models for each platform and make a prediction curve for the region of interest [5x2,5x4,5x8,5x16]\n",
      "    4. Run verification experiments so as to find that region of interest"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. Benchmark Each Task"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Constants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The benchmarking time should be 5 minutes (300 seconds). This should be shared equally between all of the tasks.\n",
      "* Each task starts with 100 paths"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "benchmarking_time = 300.0\n",
      "paths_start_value = 100\n",
      "benchmarking_time_per_task = benchmarking_time/len(option_tasks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function used for running the benchmark on a specific platform"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def platform_benchmark(platform,option_tasks,queue,):\n",
      "    for i,o in enumerate(option_tasks):\n",
      "        paths = paths_start_value\n",
      "        total_time = 0.0\n",
      "        results = []\n",
      "        while(total_time < benchmarking_time_per_task):\n",
      "            if(isinstance(platform,MulticoreCPU.MulticoreCPU)): mc_solver = MulticoreCPU_MonteCarlo.MulticoreCPU_MonteCarlo([o],paths,platform)\n",
      "            elif(isinstance(platform,OpenCLGPU.OpenCLGPU)): mc_solver = OpenCLGPU_MonteCarlo.OpenCLGPU_MonteCarlo([o],paths,platform)\n",
      "            elif(isinstance(platform,OpenCLAlteraFPGA.OpenCLAlteraFPGA)): mc_solver = OpenCLAlteraFPGA_MonteCarlo.OpenCLAlteraFPGA_MonteCarlo([o],paths,platform)\n",
      "                \n",
      "            result = mc_solver.execute()\n",
      "            results.append((paths,result[-1]/10e6,float(result[1])))\n",
      "        \n",
      "            total_time += result[-1]/10e6\n",
      "        \n",
      "            paths *= 2\n",
      "        \n",
      "        queue.put((platform.ssh_alias,i,results))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Code that launches benchmarking on separate threads"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "queue = multiprocessing.Queue()\n",
      "\n",
      "pool = [multiprocessing.Process(target=platform_benchmark,args=(p,option_tasks[0:2],queue,)) for p in platforms]\n",
      "for p in pool: p.start()\n",
      "for p in pool: \n",
      "    p.join()\n",
      "    del p\n",
      "\n",
      "#for p in platforms: platform_benchmark(p,option_tasks[0:2],queue,)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Process Process-4:\n",
        "Traceback (most recent call last):\n",
        "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
        "    self.run()\n",
        "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
        "    self._target(*self._args, **self._kwargs)\n",
        "  File \"<ipython-input-21-b15109430a73>\", line 11, in platform_benchmark\n",
        "    result = mc_solver.execute()\n",
        "  File \"/home/gordon/workspace/ForwardFinancialFramework/Platforms/MulticoreCPU/MulticoreCPU_MonteCarlo.py\", line 635, in execute\n",
        "    results = subprocess.check_output(run_cmd,env=env)\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/subprocess32.py\", line 635, in check_output\n",
        "    raise CalledProcessError(retcode, process.args, output=output)\n",
        "CalledProcessError: Command '['ssh', 'ee-mollie', 'source', '/etc/profile;', '/home/gi11/workspace/ForwardFinancialFramework/Platforms/MulticoreCPU/multicore_c_code/mc_solver_multicore_cpu_ee_mollie_bl_1_as_1', '4096', '100', '2518388176', '8', '0.0191519450379', '100', '0.129670770029', '1', '1', '110', '4096']' returned non-zero exit status 127\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Collating results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Results are an array of (paths,latency,accuracy) for each platform and task, \n",
      "\n",
      "i.e. benchmark_results[i][j] would be the results array for the jth task on the ith platform"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "while not(queue.empty()): results += [queue.get()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#platforms, tasks, results (paths, time, accuracy)\n",
      "benchmark_results = [[[] for t in range(len(option_tasks))] for p in range(len(platforms))]\n",
      "platform_names = [p.ssh_alias for p in platforms]\n",
      "\n",
      "for result in results:\n",
      "    benchmark_results[platform_names.index(result[0])][result[1]] = result[2]\n",
      "\n",
      "for p in range(len(platforms)):\n",
      "    for t in range(len(option_tasks)):\n",
      "        benchmark_results[p][t] = numpy.array(benchmark_results[p][t],dtype=[('paths','f8'),('latency','f8'),('accuracy','f8')]) #\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,p in enumerate(platforms):\n",
      "    print \"Platform \"+p.ssh_alias+\":\"\n",
      "    for j,t in enumerate(option_tasks):\n",
      "        print \"Task \"+str(j)+\":\"\n",
      "        print benchmark_results[i][j]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Platform ee-snowball2:\n",
        "Task 0:\n",
        "[(100.0, 0.1933961868286133, 0.301263)\n",
        " (200.0, 0.14581000804901123, 0.273611)\n",
        " (400.0, 0.14337658882141113, 0.114455)\n",
        " (800.0, 0.14711179733276367, 0.167544)\n",
        " (1600.0, 0.22098538875579835, 0.084308)\n",
        " (3200.0, 0.19577889442443847, 0.07133)\n",
        " (6400.0, 0.14494109153747559, 0.044361)\n",
        " (12800.0, 0.1619020938873291, 0.029569)\n",
        " (25600.0, 0.19624850749969483, 0.022722)\n",
        " (51200.0, 0.14504308700561525, 0.016402)\n",
        " (102400.0, 0.17734639644622802, 0.011935)\n",
        " (204800.0, 0.1904426097869873, 0.00789)\n",
        " (409600.0, 0.17366321086883546, 0.005762)\n",
        " (819200.0, 0.21970109939575194, 0.004028)\n",
        " (1638400.0, 0.30425429344177246, 0.00299)\n",
        " (3276800.0, 0.4361388921737671, 0.002087)\n",
        " (6553600.0, 0.6386730909347534, 0.001482)\n",
        " (13107200.0, 1.0592896938323975, 0.000994)\n",
        " (26214400.0, 2.1878856897354124, 0.000742)]\n",
        "Task 1:\n",
        "[(100.0, 0.155928897857666, 0.076846) (200.0, 0.1420921802520752, 0.350293)\n",
        " (400.0, 0.19446139335632323, 0.100032)\n",
        " (800.0, 0.14637470245361328, 0.09877)\n",
        " (1600.0, 0.20057280063629152, 0.081117)\n",
        " (3200.0, 0.15077309608459472, 0.053198)\n",
        " (6400.0, 0.14432768821716307, 0.033232)\n",
        " (12800.0, 0.16392500400543214, 0.023452)\n",
        " (25600.0, 0.19662978649139404, 0.018425)\n",
        " (51200.0, 0.1773832082748413, 0.01176)\n",
        " (102400.0, 0.16004021167755128, 0.009342)\n",
        " (204800.0, 0.2078092098236084, 0.006082)\n",
        " (409600.0, 0.20133819580078124, 0.004591)\n",
        " (819200.0, 0.20809538364410402, 0.00322)\n",
        " (1638400.0, 0.25792410373687746, 0.002145)\n",
        " (3276800.0, 0.3777873992919922, 0.00161)\n",
        " (6553600.0, 0.6193143129348755, 0.001136)\n",
        " (13107200.0, 1.0580889940261842, 0.000794)\n",
        " (26214400.0, 1.9826345920562745, 0.00056)]\n",
        "Task 2:\n",
        "[]\n",
        "Task 3:\n",
        "[]\n",
        "Task 4:\n",
        "[]\n",
        "Task 5:\n",
        "[]\n",
        "Task 6:\n",
        "[]\n",
        "Task 7:\n",
        "[]\n",
        "Task 8:\n",
        "[]\n",
        "Task 9:\n",
        "[]\n",
        "Task 10:\n",
        "[]\n",
        "Task 11:\n",
        "[]\n",
        "Task 12:\n",
        "[]\n",
        "Task 13:\n",
        "[]\n",
        "Task 14:\n",
        "[]\n",
        "Task 15:\n",
        "[]\n",
        "Task 16:\n",
        "[]\n",
        "Task 17:\n",
        "[]\n",
        "Task 18:\n",
        "[]\n",
        "Task 19:\n",
        "[]\n",
        "Task 20:\n",
        "[]\n",
        "Task 21:\n",
        "[]\n",
        "Task 22:\n",
        "[]\n",
        "Task 23:\n",
        "[]\n",
        "Task 24:\n",
        "[]\n",
        "Task 25:\n",
        "[]\n",
        "Task 26:\n",
        "[]\n",
        "Task 27:\n",
        "[]\n",
        "Task 28:\n",
        "[]\n",
        "Task 29:\n",
        "[]\n",
        "Task 30:\n",
        "[]\n",
        "Task 31:\n",
        "[]\n",
        "Task 32:\n",
        "[]\n",
        "Task 33:\n",
        "[]\n",
        "Task 34:\n",
        "[]\n",
        "Task 35:\n",
        "[]\n",
        "Task 36:\n",
        "[]\n",
        "Task 37:\n",
        "[]\n",
        "Task 38:\n",
        "[]\n",
        "Task 39:\n",
        "[]\n",
        "Task 40:\n",
        "[]\n",
        "Task 41:\n",
        "[]\n",
        "Task 42:\n",
        "[]\n",
        "Task 43:\n",
        "[]\n",
        "Task 44:\n",
        "[]\n",
        "Task 45:\n",
        "[]\n",
        "Task 46:\n",
        "[]\n",
        "Task 47:\n",
        "[]\n",
        "Task 48:\n",
        "[]\n",
        "Task 49:\n",
        "[]\n",
        "Task 50:\n",
        "[]\n",
        "Task 51:\n",
        "[]\n",
        "Task 52:\n",
        "[]\n",
        "Task 53:\n",
        "[]\n",
        "Task 54:\n",
        "[]\n",
        "Task 55:\n",
        "[]\n",
        "Task 56:\n",
        "[]\n",
        "Task 57:\n",
        "[]\n",
        "Task 58:\n",
        "[]\n",
        "Task 59:\n",
        "[]\n",
        "Task 60:\n",
        "[]\n",
        "Task 61:\n",
        "[]\n",
        "Task 62:\n",
        "[]\n",
        "Task 63:\n",
        "[]\n",
        "Task 64:\n",
        "[]\n",
        "Task 65:\n",
        "[]\n",
        "Task 66:\n",
        "[]\n",
        "Task 67:\n",
        "[]\n",
        "Task 68:\n",
        "[]\n",
        "Task 69:\n",
        "[]\n",
        "Task 70:\n",
        "[]\n",
        "Task 71:\n",
        "[]\n",
        "Task 72:\n",
        "[]\n",
        "Task 73:\n",
        "[]\n",
        "Task 74:\n",
        "[]\n",
        "Task 75:\n",
        "[]\n",
        "Task 76:\n",
        "[]\n",
        "Task 77:\n",
        "[]\n",
        "Task 78:\n",
        "[]\n",
        "Task 79:\n",
        "[]\n",
        "Task 80:\n",
        "[]\n",
        "Task 81:\n",
        "[]\n",
        "Task 82:\n",
        "[]\n",
        "Task 83:\n",
        "[]\n",
        "Task 84:\n",
        "[]\n",
        "Task 85:\n",
        "[]\n",
        "Task 86:\n",
        "[]\n",
        "Task 87:\n",
        "[]\n",
        "Task 88:\n",
        "[]\n",
        "Task 89:\n",
        "[]\n",
        "Task 90:\n",
        "[]\n",
        "Task 91:\n",
        "[]\n",
        "Task 92:\n",
        "[]\n",
        "Task 93:\n",
        "[]\n",
        "Task 94:\n",
        "[]\n",
        "Task 95:\n",
        "[]\n",
        "Task 96:\n",
        "[]\n",
        "Task 97:\n",
        "[]\n",
        "Task 98:\n",
        "[]\n",
        "Task 99:\n",
        "[]\n",
        "Task 100:\n",
        "[]\n",
        "Task 101:\n",
        "[]\n",
        "Task 102:\n",
        "[]\n",
        "Task 103:\n",
        "[]\n",
        "Task 104:\n",
        "[]\n",
        "Task 105:\n",
        "[]\n",
        "Task 106:\n",
        "[]\n",
        "Task 107:\n",
        "[]\n",
        "Task 108:\n",
        "[]\n",
        "Task 109:\n",
        "[]\n",
        "Task 110:\n",
        "[]\n",
        "Task 111:\n",
        "[]\n",
        "Task 112:\n",
        "[]\n",
        "Task 113:\n",
        "[]\n",
        "Task 114:\n",
        "[]\n",
        "Task 115:\n",
        "[]\n",
        "Task 116:\n",
        "[]\n",
        "Task 117:\n",
        "[]\n",
        "Task 118:\n",
        "[]\n",
        "Task 119:\n",
        "[]\n",
        "Task 120:\n",
        "[]\n",
        "Task 121:\n",
        "[]\n",
        "Task 122:\n",
        "[]\n",
        "Task 123:\n",
        "[]\n",
        "Task 124:\n",
        "[]\n",
        "Task 125:\n",
        "[]\n",
        "Task 126:\n",
        "[]\n",
        "Task 127:\n",
        "[]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}